import json
import logging
from os import getenv

import grpc.aio
from google import genai
from google.genai import types

import nest_pb2
import nest_pb2_grpc

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)


class STTService:
    _METADATA = (("authorization", f"Bearer {getenv("CLOVA_SPEECH_SECRET_KEY")}"),)
    client = genai.Client(api_key=getenv("GEMINI_API_KEY"))

    def __init__(self, on_finished):
        self._pcm_iter = None
        self.finished_callback = on_finished

    async def _generate_requests(self):
        yield nest_pb2.NestRequest(
            type=nest_pb2.RequestType.CONFIG,
            config=nest_pb2.NestConfig(
                config=json.dumps(
                    {
                        "transcription": {
                            "language": "ko",
                        },
                        "semanticEpd": {
                            "usePeriodEpd": True,
                        },
                    }
                )
            ),
        )

        async for pcm, seq_id, ep_flag in self._pcm_iter:
            logger.debug(f"seq_id: {seq_id}, ep_flag: {ep_flag}")
            yield nest_pb2.NestRequest(
                type=nest_pb2.RequestType.DATA,
                data=nest_pb2.NestData(
                    chunk=pcm,
                    extra_contents=json.dumps({"seqId": seq_id, "epFlag": ep_flag}),
                ),
            )

    async def run(self, pcm_iter):
        self._pcm_iter = pcm_iter

        channel = grpc.aio.secure_channel(
            "clovaspeech-gw.ncloud.com:50051", grpc.ssl_channel_credentials()
        )
        stub = nest_pb2_grpc.NestServiceStub(channel)

        buffer = []

        try:
            # ì„œë²„ë¡œë¶€í„° ì‘ë‹µì„ ë°˜ë³µ ì²˜ë¦¬
            responses = stub.recognize(
                self._generate_requests(), metadata=self._METADATA
            )
            async for response in responses:
                content = json.loads(response.contents)
                transcription = content.get("transcription")
                if not transcription:
                    logger.info(f"response: {content}")
                    continue

                text = transcription.get("text")
                if text:
                    buffer.append(text)
                    logger.debug(f"ğŸ”¹ Partial: {text}")
                else:
                    logger.info(f"response: {content}")

        except grpc.aio.AioRpcError as e:
            # gRPC ì˜¤ë¥˜ ì²˜ë¦¬
            logger.error(f"Error: {e.details()}")
        finally:
            await channel.close()  # ì‘ì—…ì´ ëë‚˜ë©´ ì±„ë„ ë‹«ê¸°

        result = "".join(buffer)
        if result:
            await self.finished_callback(result)
        return result

    async def correct_text(self, result: str):
        response = await self.client.aio.models.generate_content(
            model="gemini-2.0-flash-lite",
            contents=result,
            config=types.GenerateContentConfig(
                system_instruction=[
                    "ë¬¸ì¥ì˜ ì˜¤íƒ€ë¥¼ ìˆ˜ì •í•˜ê³ , ë¬¸ì¥ì´ ëë‚˜ë©´ ì–´ìš¸ë¦¬ëŠ” ë¬¸ì¥ ë¶€í˜¸(ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ ë“±)ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ê°€í•´ ì£¼ì„¸ìš”.",
                    "ì¡´ëŒ“ë§ê³¼ ë°˜ë§ ë“± ë§íˆ¬ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€í•´ ì£¼ì„¸ìš”.",
                    "ë¬¸ì¥ì„ ë°”ê¾¸ê±°ë‚˜ í•´ì„í•˜ì§€ ë§ê³ , ìµœëŒ€í•œ ì›ë˜ ì˜ë¯¸ë¥¼ ìœ ì§€í•´ ì£¼ì„¸ìš”.",
                ]
            ),
        )

        return response.text.strip()
